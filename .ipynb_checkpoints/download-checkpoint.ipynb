{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219e066e-03cc-4418-b8dc-5f2ea163538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyAN_r75StfQrM_MRTr9F52_d92h226hYFg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33df4e5-3b9e-4b67-90c3-4957c74278a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def get_comments_with_time(video_id, api_key=API_KEY, target_count=200):\n",
    "    comments = []\n",
    "    url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
    "    params = {\n",
    "        'part': 'snippet',\n",
    "        'videoId': video_id,\n",
    "        'key': api_key,\n",
    "        'textFormat': 'plainText',\n",
    "        'maxResults': 100,\n",
    "        'fields': 'items(snippet/topLevelComment/snippet(textDisplay,publishedAt)),nextPageToken'\n",
    "    }\n",
    "\n",
    "    page = 0\n",
    "    while len(comments) < target_count:\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        data = response.json()\n",
    "\n",
    "        for item in data.get(\"items\", []):\n",
    "            snippet = item['snippet']['topLevelComment']['snippet']\n",
    "            comment_text = snippet['textDisplay']\n",
    "            published_time = snippet['publishedAt']\n",
    "            comments.append((comment_text, published_time))  # now a tuple\n",
    "\n",
    "            if len(comments) >= target_count:\n",
    "                break\n",
    "\n",
    "        if 'nextPageToken' in data:\n",
    "            params['pageToken'] = data['nextPageToken']\n",
    "        else:\n",
    "            print(\"No more comments available.\")\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "        print(f\"Fetched: {len(comments)} comments\")\n",
    "        time.sleep(0.1)  # Delay to prevent quota spikes\n",
    "\n",
    "    return comments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541ce3db-1ab6-4c22-a39c-5aea1bf648bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched: 100 comments\n",
      "Fetched: 200 comments\n",
      "Fetched: 300 comments\n",
      "Fetched: 400 comments\n"
     ]
    }
   ],
   "source": [
    "c=get_comments_with_time(\"EerdGm-ehJQ\",API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e5ba81d-20b6-494e-8f0b-271d3eb78157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Issues and Solutions:\\nThere's a YouTube glitch with the timestamps. You can also find them in the description.\\nLesson 15 - DayJS ESM version doesn't load. Use this instead:\\nimport dayjs from 'https://unpkg.com/supersimpledev@8.5.0/dayjs/esm/index.js';\\n(unpkg changed their backend behavior and the original import doesn't work anymore)\\nNote: I am unable to see replies to this comment. If you have questions, please create a new comment.\",\n",
       "  '2024-05-09T04:04:49Z'),\n",
       " ('completed! thankful for this recourse', '2025-10-12T04:10:26Z'),\n",
       " ('2.5 hours in and I can say that this course is indeed very useful and well made!',\n",
       "  '2025-10-11T18:04:53Z'),\n",
       " ('oh!!! my asian guy', '2025-10-11T16:58:56Z'),\n",
       " ('20:55:50', '2025-10-11T16:45:38Z'),\n",
       " ('20-9-25 - Day 1 - 33:18\\r\\n21-9-25 - Day 2 - 45:18\\r\\n22-9-25 - Day 3 - 49:52\\r\\n23-9-25 -  Day 4 - 1:43:18\\r\\n24-9-25-  Day 5 - 2:09:39\\r\\n25-09-25 - Day 6 - 3:10:10\\r\\n26-09-25 - Day 7 - 3:19:00\\r\\n27-09-25 - Day 8 - 3:40:00\\r\\n02-10-25 - Day 9 - 3:46:49\\r\\n\\r04-10-25 - Day 10 - 3:55:50\\r\\n07-10-25 - Day 11 -  4:06:00\\r\\n08-10-25 - Day 12 -4:30:00\\r\\n09-10-25 - Day 13 - 4:34:00\\r\\n10-10-25 - Day 14  - 4:37:00\\r\\n\\r11-10-25 - Day 15 -  4:44:00',\n",
       "  '2025-10-11T16:37:33Z'),\n",
       " ('The quality of this video is excellent.', '2025-10-11T14:28:11Z'),\n",
       " (\"the starting date for me is 11 oct , I'll not comment until I complete this course\",\n",
       "  '2025-10-11T14:09:06Z'),\n",
       " ('Any Indian here ? ðŸ‘‹ðŸ˜„', '2025-10-11T13:35:46Z'),\n",
       " ('2:14:00', '2025-10-11T12:44:45Z'),\n",
       " ('ðŸ”– bookmarks 4:05:00', '2025-10-11T05:00:01Z'),\n",
       " ('Rock Pare Scissors at 2:49:37', '2025-10-10T23:56:54Z'),\n",
       " ('My dear friend! HOPE ALL THE DEV COMMUNITY LEARN FROM YOUR TEACHINGS! Your videos have saved my 4SS several times, and now, due to this, I had an interview with Cursor AI. Keep the good content!',\n",
       "  '2025-10-10T23:48:45Z'),\n",
       " ('Day 1 of learning Javascript, October 10 2025, remind me in December 10 2025',\n",
       "  '2025-10-10T19:33:05Z'),\n",
       " ('Helpful content, thank you.', '2025-10-10T18:04:31Z'),\n",
       " ('20-9-25 - Day 1 - 33:18\\r\\n21-9-25 - Day 2 - 45:18\\r\\n22-9-25 - Day 3 - 49:52\\r\\n23-9-25 -  Day 4 - 1:43:18\\r\\n24-9-25-  Day 5 - 2:09:39\\r\\n25-09-25 - Day 6 - 3:10:10\\r\\n26-09-25 - Day 7 - 3:19:00\\r\\n27-09-25 - Day 8 - 3:40:00\\r\\n02-10-25 - Day 9 - 3:46:49\\r\\n\\r04-10-25 - Day 10 - 3:55:50\\r\\n07-10-25 - Day 11 -  4:06:00\\r\\n08-10-25 - Day 12 -4:30:00\\r\\n09-10-25 - Day 13 - 4:34:00\\n10-10-25 - Day 14  - 4:37:00',\n",
       "  '2025-10-10T16:57:07Z'),\n",
       " ('The cart reset button is malfunctioning here', '2025-10-10T10:23:34Z'),\n",
       " (\"Hey Simon, some times ago, I started learning JS using another youtuber's tutorial. I couldn't continue as it was so harder to understand to the point I told my mentor that I cannot learn this thing because of its difficulty. But sincerely, he sent me this tutorial and I am flowing. Good you are\\nGod bless you richly\\n\\nFrom Sierra Leone\",\n",
       "  '2025-10-10T08:24:26Z'),\n",
       " ('Day 1 43:26\\nDay 2 1:51:14\\nDay 3 2:50:08', '2025-10-10T08:16:16Z'),\n",
       " ('this is just a legendary teaching brother. Nice', '2025-10-10T04:59:28Z')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca2fbae-ea55-437b-8ea2-352823414cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_top_videos(query, api_key=API_KEY, max_results=10):\n",
    "    url = \"https://www.googleapis.com/youtube/v3/search\"\n",
    "    params = {\n",
    "        \"part\": \"snippet\",\n",
    "        \"q\": query,\n",
    "        \"type\": \"video\",\n",
    "        \"maxResults\": max_results,\n",
    "        \"key\": api_key\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    videos = []\n",
    "    for item in data.get(\"items\", []):\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        title = item[\"snippet\"][\"title\"]\n",
    "        videos.append((video_id, title))\n",
    "        \n",
    "    return videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d37239-5ede-449b-95fa-226ca61f3833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_video_sentiment(video_id, model, tokenizer):\n",
    "    comments = get_comments_with_time(video_id)\n",
    "    \n",
    "    sentiments = []\n",
    "    for comment, time in comments:\n",
    "        sentiment = predict_sentiment(comment, model, tokenizer)  # your existing function\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    # summary\n",
    "    positive = sentiments.count(\"positive\")\n",
    "    negative = sentiments.count(\"negative\")\n",
    "    \n",
    "    return {\n",
    "        \"video_id\": video_id,\n",
    "        \"positive\": positive,\n",
    "        \"negative\": negative,\n",
    "        \"neutral\": neutral\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d27bd8-88da-4e82-962c-b86c2ca76830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "def top_10_sentiment_page():\n",
    "    st.title(\"Top 10 YouTube Video Sentiment Comparison\")\n",
    "    \n",
    "    query = st.text_input(\"Enter Search Query (e.g., AI tools)\")\n",
    "    \n",
    "    if st.button(\"Search\"):\n",
    "        videos = get_top_videos(query)\n",
    "        results = []\n",
    "\n",
    "        for video_id, title in videos:\n",
    "            st.write(f\"Analyzing: {title}\")\n",
    "            summary = analyze_video_sentiment(video_id, model, tokenizer)\n",
    "            summary[\"title\"] = title\n",
    "            results.append(summary)\n",
    "\n",
    "        st.write(\"### Sentiment Summary for Top 10 Videos\")\n",
    "        st.table(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c8778-c565-4c0c-b5d0-9399f8b2e814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
